{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fdcff07-cef5-4ead-ba06-57b1cdf1e351",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
    "from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "from array import array\n",
    "import jellyfish\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image, ImageFilter, ImageOps\n",
    "import sys\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "from skimage import color, filters, exposure, io\n",
    "from skimage.morphology import closing,footprint_rectangle \n",
    "from skimage.restoration import denoise_tv_chambolle\n",
    "from skimage.exposure import equalize_adapthist\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e652c072-b180-471f-a4b8-65214124d989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nEND - Authenticate\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Authenticate\n",
    "Authenticates your credentials and creates a client.\n",
    "'''\n",
    "var = json.load(open(\"credidentials.json\"))\n",
    "subscription_key= var[\"API_KEY\"]\n",
    "endpoint = var[\"END_POINT\"]\n",
    "computervision_client = ComputerVisionClient(endpoint, CognitiveServicesCredentials(subscription_key))\n",
    "'''\n",
    "END - Authenticate\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7a3c836-fe81-4cb8-9256-a09ec864bd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lucces in resolvarea\n",
      "TEMELOR la\n",
      "LABORA toarele de\n",
      "Inteligenta Artificialà!\n",
      "\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# img = open(\"test1.png\", \"rb\")\n",
    "img = open(\"test2.jpeg\", \"rb\")\n",
    "read_response = computervision_client.read_in_stream(\n",
    "    image=img,\n",
    "    mode=\"Printed\",\n",
    "    raw=True\n",
    ")\n",
    "# print(read_response.as_dict())\n",
    "\n",
    "operation_id = read_response.headers['Operation-Location'].split('/')[-1]\n",
    "while True:\n",
    "    read_result = computervision_client.get_read_result(operation_id)\n",
    "    if read_result.status not in ['notStarted', 'running']:\n",
    "        break\n",
    "    time.sleep(1)\n",
    "\n",
    "# Print the detected text, line by line\n",
    "result = []\n",
    "if read_result.status == OperationStatusCodes.succeeded:\n",
    "    for text_result in read_result.analyze_result.read_results:\n",
    "        for line in text_result.lines:\n",
    "            print(line.text)\n",
    "            result.append(line.text)\n",
    "\n",
    "print()\n",
    "# get/define the ground truth\n",
    "# groundTruth = [\"Google Cloud\", \"Platform\"]\n",
    "groundTruth = [\"Succes in rezolvarea\", \"tEMELOR la\", \"LABORAtoaree de\", \"Inteligenta Artificiala!\"]\n",
    "\n",
    "# compute the performance\n",
    "noOfCorrectLines = sum(i == j for i, j in zip(result, groundTruth))\n",
    "print(noOfCorrectLines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fea15c2e-e97b-484a-8842-9834321f4b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path): \n",
    "#Preprocesarea imaginii:\n",
    "#daca are 4 canale rgba, eliminam canalul alpha\n",
    "#reducerea zgomotul\n",
    "#conversia in grayscale\n",
    "#ajustarea contrastul\n",
    "#binarizarea: calcularea pragului Otsu \n",
    "#aplicarea operatiilor morfologice\n",
    "#conversia in format uint8\n",
    "    img = io.imread(image_path)\n",
    "\n",
    "    if img.ndim == 3 and img.shape[-1] == 4:\n",
    "        img = img[:, :, :3]\n",
    "    img_zgomot = cv2.medianBlur(img, 5)\n",
    "    img_gray = color.rgb2gray(img_zgomot)\n",
    "    img_contrast = exposure.rescale_intensity(img_gray, in_range=(0.05, 0.95))\n",
    "    prag_otsu = filters.threshold_otsu(img_contrast)\n",
    "    img_binar = img_contrast > prag_otsu\n",
    "    img_closing = closing(img_binar, footprint_rectangle((3, 3)))\n",
    "    img_result = (img_closing * 255).astype(np.uint8)\n",
    "\n",
    "    cv2.imwrite(\"imagine_procesata_test2.jpeg\",img_result)\n",
    "    return img_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1a428ab-6897-42e8-ade2-70f3610bd6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distanta_hamming(secv1, secv2):\n",
    "#distanta Hamming \n",
    "    n=len(secv1)\n",
    "    m=len(secv2)\n",
    "    if n != m:\n",
    "        raise ValueError(\"Distanta Hamming merge doar pe siruri de aceeasi lungime\")\n",
    "    return sum(c1 != c2 for c1, c2 in zip(secv1, secv2))\n",
    "    \n",
    "def distanta_jaro_winkler(secv1, secv2):\n",
    "#distanta Jaro-Winkler \n",
    "    return 1 - jellyfish.jaro_winkler_similarity(secv1, secv2)\n",
    "\n",
    "def distanta_levenshtein(secv1, secv2):\n",
    "#distanta Levenshtein \n",
    "    n=len(secv1)\n",
    "    m=len(secv2)\n",
    "    if n < m:\n",
    "        return distanta_levenshtein(secv2, secv1)\n",
    "    if m == 0:\n",
    "        return n\n",
    "    anterior = list(range(m + 1))\n",
    "    for i, c1 in enumerate(secv1):\n",
    "        curent = [i + 1]\n",
    "        for j, c2 in enumerate(secv2):\n",
    "            insertii = anterior[j + 1] + 1\n",
    "            stergeri = curent[j] + 1\n",
    "            substitutii = anterior[j] + (c1 != c2)\n",
    "            curent.append(min(insertii, stergeri, substitutii))\n",
    "        anterior = curent\n",
    "    return anterior[-1]\n",
    "    \n",
    "def distanta_lcs(secv1, secv2):\n",
    "#Longest Common Subsequence (LCS)\n",
    "    n = len(secv1)\n",
    "    m = len(secv2)\n",
    "    matr = [[0] * (m + 1) for _ in range(n + 1)]\n",
    "    \n",
    "    for i in range(1, n + 1):\n",
    "        for j in range(1, m + 1):\n",
    "            if secv1[i - 1] == secv2[j - 1]:\n",
    "                matr[i][j] = matr[i - 1][j - 1] + 1\n",
    "            else:\n",
    "                matr[i][j] = max(matr[i - 1][j], matr[i][j - 1])\n",
    "    return matr[n][m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b371e04b-520e-40b0-9766-79d16833b21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cer_calcul(text_recunoscut, text_real):\n",
    "#Character Error Rate (CER)\n",
    "    if not text_real:\n",
    "        return 0\n",
    "    dist = distanta_levenshtein(text_recunoscut, text_real)\n",
    "    return dist / len(text_real)\n",
    "\n",
    "def wer_calcul(text_recunoscut, text_real):\n",
    "#Word Error Rate (WER) \n",
    "    cuvinte_recunoscute = text_recunoscut.split()\n",
    "    cuvinte_reale = text_real.split()\n",
    "    if not cuvinte_reale:\n",
    "        return 0\n",
    "    dist = distanta_levenshtein(cuvinte_recunoscute, cuvinte_reale)\n",
    "    return dist / len(cuvinte_reale)\n",
    "\n",
    "def iou_calcul(boxA, boxB):\n",
    "#Intersection over Union (IoU) \n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83e44955-d895-4d8f-99fe-5594c0f71275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr(img, computervision):\n",
    "#realizeaza OCR pe imaginea data \n",
    "    raspuns = computervision.read_in_stream(\n",
    "        image=img,\n",
    "        mode=\"Printed\",\n",
    "        raw=True\n",
    "    )\n",
    "\n",
    "    locatia = raspuns.headers[\"Operation-Location\"]\n",
    "    id_operatie = locatia.split(\"/\")[-1]\n",
    "\n",
    "    while True:\n",
    "        rez = computervision.get_read_result(id_operatie)\n",
    "        if rez.status.lower() not in ['notstarted', 'running']:\n",
    "            break\n",
    "        time.sleep(1)\n",
    "\n",
    "    text_recunoscut = \"\"\n",
    "    boxes = []\n",
    "    if rez.status == \"succeeded\":\n",
    "        for pag in rez.analyze_result.read_results:\n",
    "            for linie in pag.lines:\n",
    "                text_recunoscut += linie.text + \"\\n\"\n",
    "                pct = linie.bounding_box\n",
    "                x_coord = pct[0::2]\n",
    "                y_coord = pct[1::2]\n",
    "                x_min, x_max = min(x_coord), max(x_coord)\n",
    "                y_min, y_max = min(y_coord), max(y_coord)\n",
    "\n",
    "                box = (x_min, y_min, x_max, y_max)\n",
    "                boxes.append(box)\n",
    "\n",
    "    return text_recunoscut.strip(), boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0207ba5-2d3d-47d4-bc06-584bcba9d4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluare(text_recunoscut, text_real):\n",
    "#evaluare cu o singura metrica   --- 1A\n",
    "    cer = cer_calcul(text_recunoscut, text_real)\n",
    "    wer = wer_calcul(text_recunoscut, text_real)\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(\"Evaluare folosind Levenshtein\")\n",
    "    print(\"Character Error Rate (CER):\", cer)\n",
    "    print(\"Word Error Rate (WER):\", wer)\n",
    "\n",
    "def evaluare2(text_recunoscut, text_real):\n",
    "#evaluare cu mai multe metrici   --- 1B\n",
    "    metrici = {}\n",
    "    try:\n",
    "        cer = cer_calcul(text_recunoscut, text_real)\n",
    "        wer = wer_calcul(text_recunoscut, text_real)\n",
    "        metrici[\"levenshtein_cer\"] = cer\n",
    "        metrici[\"levenshtein_wer\"] = wer\n",
    "    except Exception as e:\n",
    "        print(f\"Eroare la calcularea CER/WER: {e}\")\n",
    "        metrici[\"levenshtein_cer\"] = \"Eroare\"\n",
    "        metrici[\"levenshtein_wer\"] = \"Eroare\"\n",
    "\n",
    "    try:\n",
    "        if len(text_recunoscut) == len(text_real):\n",
    "            hamming = distanta_hamming(text_recunoscut, text_real) / len(text_real)\n",
    "            metrici[\"hamming_cer\"] = hamming\n",
    "    except ValueError as ve:\n",
    "        metrici[\"hamming_cer\"] = str(ve)\n",
    "    except Exception as e:\n",
    "        print(f\"Eroare la calcularea Hamming distance: {e}\")\n",
    "        metrici[\"hamming_cer\"] = \"Eroare\"\n",
    "\n",
    "    try:\n",
    "        if jellyfish is not None:\n",
    "            jaro_winkler = distanta_jaro_winkler(text_recunoscut, text_real)\n",
    "            metrici[\"jaro_winkler_cer\"] = jaro_winkler\n",
    "    except Exception as e:\n",
    "        print(f\"Eroare la calcularea Jaro-Winkler: {e}\")\n",
    "        metrici[\"jaro_winkler_cer\"] = \"Eroare\"\n",
    "\n",
    "    try:\n",
    "        lcs_length = distanta_lcs(text_recunoscut, text_real)\n",
    "        metrici[\"lcs\"] = lcs_length\n",
    "    except Exception as e:\n",
    "        print(f\"Eroare la calcularea LCS: {e}\")\n",
    "        metrici[\"lcs\"] = \"Eroare\"\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"Evaluare folosind mai multe metrici\")\n",
    "    for key, value in metrici.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "def calitate(boxes,box_real):\n",
    "#calitatea localizarii textului   --- 2\n",
    "    nr_boxes = min(len(boxes), len(box_real))\n",
    "    for i in range(nr_boxes):\n",
    "        iou = iou_calcul(boxes[i], box_real[i])\n",
    "        print(\"\\n\")\n",
    "        print(\"Calitatea localizării textului (IoU):\", iou)\n",
    "    if len(boxes) > len(box_real):\n",
    "        print(f\"Sunt {len(boxes) - len(box_real)} box-uri suplimentare.\")\n",
    "    elif len(box_real) > len(boxes):\n",
    "        print(f\"Lipsesc {len(box_real) - len(boxes)} box-uri reale.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b1e1f1d-7418-444c-8754-35e15228c5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Textul recunoscut de OCR:\n",
      "Lucces in resolvarea\n",
      "AEMELOR la\n",
      "LABORA toarele de\n",
      "Inteligentà Artificialà!\n",
      ".\n",
      "\n",
      "\n",
      "Bounding boxes\n",
      "(72.0, 293.0, 1336.0, 476.0)\n",
      "(128.0, 578.0, 1059.0, 739.0)\n",
      "(80.0, 915.0, 1010.0, 1043.0)\n",
      "(101.0, 1132.0, 1452.0, 1295.0)\n",
      "(152.0, 1342.0, 167.0, 1365.0)\n",
      "\n",
      "\n",
      "Textul real de OCR:\n",
      "Succes in rezolvarea tEMELOR la LABORAtoaree de Inteligenta Artificiala!\n",
      "\n",
      "\n",
      "Bounding boxes reale\n",
      "(70, 305, 1335, 430)\n",
      "(130, 590, 1050, 710)\n",
      "(80, 925, 1010, 1025)\n",
      "(100, 1140, 1450, 1285)\n",
      "\n",
      "\n",
      "Evaluare folosind Levenshtein\n",
      "Character Error Rate (CER): 0.16666666666666666\n",
      "Word Error Rate (WER): 0.8888888888888888\n",
      "\n",
      "\n",
      "Evaluare folosind mai multe metrici\n",
      "levenshtein_cer: 0.16666666666666666\n",
      "levenshtein_wer: 0.8888888888888888\n",
      "jaro_winkler_cer: 0.16783250862198218\n",
      "lcs: 64\n",
      "\n",
      "\n",
      "Calitatea localizării textului (IoU): 0.6835012789040907\n",
      "\n",
      "\n",
      "Calitatea localizării textului (IoU): 0.7380980766173899\n",
      "\n",
      "\n",
      "Calitatea localizării textului (IoU): 0.7829457364341085\n",
      "\n",
      "\n",
      "Calitatea localizării textului (IoU): 0.8883420319640877\n",
      "Sunt 1 box-uri suplimentare.\n"
     ]
    }
   ],
   "source": [
    "#img = open(\"test1.png\", \"rb\")\n",
    "#img=open(\"test2.jpeg\",\"rb\")\n",
    "#img=open(\"test3.jpg\",\"rb\")\n",
    "img_r = preprocess_image(\"test2.jpeg\")\n",
    "img = open(\"imagine_procesata_test2.jpeg\", \"rb\")\n",
    "text_recunoscut, boxes = ocr(img, computervision_client)\n",
    "\n",
    "print(\"Textul recunoscut de OCR:\")\n",
    "print(text_recunoscut)\n",
    "print(\"\\n\")\n",
    "print(\"Bounding boxes\")\n",
    "for box in boxes:\n",
    "    print(box)\n",
    "\n",
    "#pt test1\n",
    "#text_real = \"Google Cloud Platform\"\n",
    "#box_real = [(170, 40, 415, 90),(235, 110, 350, 145)]\n",
    "\n",
    "#pt test2\n",
    "text_real = \"Succes in rezolvarea tEMELOR la LABORAtoaree de Inteligenta Artificiala!\"\n",
    "box_real = [(70, 305, 1335, 430),(130, 590, 1050, 710),(80, 925, 1010, 1025),(100, 1140, 1450, 1285)]\n",
    "\n",
    "\n",
    "#pt test3\n",
    "#text_real = \"Optical Character Recognition\"\n",
    "#box_real = [(332, 284, 942, 393),(448, 397, 830, 488)]\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Textul real de OCR:\")\n",
    "print(text_real)\n",
    "print(\"\\n\")\n",
    "print(\"Bounding boxes reale\")\n",
    "for box in box_real:\n",
    "    print(box)\n",
    "\n",
    "evaluare(text_recunoscut, text_real)\n",
    "evaluare2(text_recunoscut, text_real)\n",
    "calitate(boxes,box_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2db867ac-bf3e-4821-ba02-201850d22d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#posibilitati de imbunatatire   --- 3\n",
    "# Preprocesarea imaginii:\n",
    "# (Reducerea zgomotului; Ajustarea contrastului; Binarizare: Otsu thresholding; Corectarea geometriei imaginii; Operatii morfologice pentru unirea textului)\n",
    "\n",
    "# Model OCR mai performant:\n",
    "# (Folosirea unui model avansat; Fine-tuning pe dataset personalizat)\n",
    "\n",
    "# Postprocesarea textului:\n",
    "# (Corectarea ortografica; Dictionar personalizat; Corectare gramaticală automată)\n",
    "\n",
    "# Imbunatatirea localizarii textului:\n",
    "# (Îmbunătățirea box-urilor; Unificarea box-urilor pentru textul divizat)\n",
    "\n",
    "# Antrenare personalizată:\n",
    "# (Fine-tuning pe imagini specifice; Detectarea fonturilor si stilurilor speciale)\n",
    "\n",
    "# Combinarea mai multor surse OCR:\n",
    "# (Combinați metode OCR diferite pentru rezultate mai precise; Validare prin vot majoritar)\n",
    "\n",
    "# Model de limbaj context-aware:\n",
    "# (Folosirea unui model de limbaj)\n",
    "\n",
    "# Ajustarea parametrilor OCR:\n",
    "# (Fine-tuning-ul setărilor OCR pentru optimizarea rezultatelor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
